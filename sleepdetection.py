# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P2qoQNwuQ9ltKQzdxm1cEpNJEHyd7uW_
"""

!pip install mediapipe opencv-python

from google.colab.patches import cv2_imshow
import cv2
import mediapipe as mp
import numpy as np
from IPython.display import display, Javascript
from google.colab import output
from PIL import Image
import base64
from io import BytesIO

# JavaScript ile video başlatma
def start_camera():
    display(Javascript('''
        async function captureImage() {
            const video = document.createElement('video');
            video.width = 640;
            video.height = 480;
            video.autoplay = true;

            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            document.body.appendChild(video);

            const canvas = document.createElement('canvas');
            canvas.width = video.width;
            canvas.height = video.height;

            const context = canvas.getContext('2d');

            // Her 100ms'de bir görüntüyü yakala ve Python'a gönder
            setInterval(() => {
                context.drawImage(video, 0, 0, video.width, video.height);
                const dataUrl = canvas.toDataURL('image/jpeg');
                google.colab.kernel.invokeFunction('notebook.capture', [dataUrl], {});
            }, 100);
        }
        captureImage();
    '''))

# Gözlerin kapalı olup olmadığını kontrol eden fonksiyon
def is_eye_closed(eye_landmarks, img_shape):
    x_min = min([int(lm.x * img_shape[1]) for lm in eye_landmarks])
    x_max = max([int(lm.x * img_shape[1]) for lm in eye_landmarks])
    y_min = min([int(lm.y * img_shape[0]) for lm in eye_landmarks])
    y_max = max([int(lm.y * img_shape[0]) for lm in eye_landmarks])

    eye_height = y_max - y_min
    eye_width = x_max - x_min

    # Eğer göz yüksekliği genişliğine oranla çok küçükse, göz kapalıdır
    return eye_height < 0.2 * eye_width  # Eşik değer ayarlanabilir

# Python tarafında görüntü yakalama ve işleme
def capture(dataUrl):
    # Base64 ile alınan veriyi numpy array'e dönüştür
    img_data = base64.b64decode(dataUrl.split(',')[1])
    img = Image.open(BytesIO(img_data))

    # Görüntüyü numpy formatına çevir ve renk düzenini ayarla
    img_np = np.array(img)
    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

    # Mediapipe FaceMesh
    mpFaceMesh = mp.solutions.face_mesh
    faceMesh = mp.solutions.face_mesh.FaceMesh(max_num_faces=1)
    mpDraw = mp.solutions.drawing_utils
    drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=1)

    # RGB olarak Mediapipe'e gönder
    imgRGB = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)
    results = faceMesh.process(imgRGB)

    LEFT_EYE = [33, 160, 158, 133, 153, 144]  # Sol göz noktaları
    RIGHT_EYE = [362, 385, 386, 263, 373, 380]  # Sağ göz noktaları

    eyes_closed = False

    # Eğer yüz algılanmışsa, mesh çiz ve göz durumunu kontrol et
    if results.multi_face_landmarks:
        for faceLms in results.multi_face_landmarks:
            mpDraw.draw_landmarks(img_np, faceLms, mpFaceMesh.FACEMESH_TESSELATION, drawSpec, drawSpec)

            # Göz noktalarını al
            left_eye = [faceLms.landmark[i] for i in LEFT_EYE]
            right_eye = [faceLms.landmark[i] for i in RIGHT_EYE]

            # Göz kapalı mı diye kontrol et
            left_eye_closed = is_eye_closed(left_eye, img_np.shape)
            right_eye_closed = is_eye_closed(right_eye, img_np.shape)

            # Eğer her iki göz kapalıysa
            if left_eye_closed and right_eye_closed:
                eyes_closed = True

    # Mesaj ekrana yazdır
    if eyes_closed:
        cv2.putText(img_np, "Uyuyor", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    else:
        cv2.putText(img_np, "Uyanik", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Görüntüyü ekranda göster
    cv2_imshow(img_np)

# Kamerayı başlat
start_camera()

# Python tarafında gelen görüntüleri yakalamak için capture fonksiyonunu bağla
output.register_callback('notebook.capture', capture)